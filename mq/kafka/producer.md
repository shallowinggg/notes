---
layout: default
title: 生产者
parent: Kafka
grand_parent: 消息队列
---

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>

## 简介

发送数据到`Kafka`的主要步骤如下所示：

![](https://raw.githubusercontent.com/shallowinggg/notes/main/images/kafka/produce.png)

我们通过创建 ProducerRecord 开始向 `Kafka` 生成消息，其中必须包含我们要将记录发送到的主题和一个值。或者，我们还可以指定一个键、一个分区、一个时间戳和/或一个标头集合。一旦我们发送 ProducerRecord，生产者要做的第一件事就是将键和值对象序列化为字节数组，以便它们可以通过网络发送。

接下来，如果我们没有显式指定分区，数据将发送到分区器。分区器会为我们选择一个分区，通常基于ProducerRecord键。一旦选择了分区，生产者就知道记录将转到哪个主题和分区。然后，它将记录添加到一批记录中，这些记录也将发送到同一主题和分区。一个单独的线程负责将这些批次的记录发送到适当的 `Kafka` `broker`。

当`broker`收到消息时，它会发回响应。如果消息成功写入 `Kafka`，它将返回一个 RecordMetadata 对象，其中包含主题、分区以及分区内记录的偏移量。如果`broker`无法写入消息，它将返回错误。当生产者收到错误时，它可能会在放弃并返回错误之前重试发送消息几次。

## 构造生产者

`Kafka` 生产者拥有三个必需配置：

- `bootstrap.servers`： 生产者将用来建立与 `Kafka` 集群的初始连接的`broker`的`host:port`对的列表。该列表不需要包含所有`broker`，因为生产者将在初始连接后获得更多信息。但建议至少包含两个，这样万一其中一个`broker`出现故障，生产者仍然能够连接到集群。
- `key.serializer`： 用于序列化将生成到 `Kafka` 的记录的键的类的名称。即使只想发送值，也需要设置 `key.serializer`，但可以对键使用 `VoidSerializer` 和 `Void` 类型。
- `value.serializer`：用于序列化将生成到 `Kafka` 的记录的值的类的名称。

## 发送消息

发送消息有三种主要方法：

- 即发即忘（Fire-and-forget）：我们将消息发送到服务器，并不真正关心它是否成功到达。大多数情况下，它会成功到达，因为 `Kafka` 具有高可用性，并且生产者会自动重试发送消息。然而，如果出现不可重试的错误或超时，消息将丢失，应用程序将无法获得任何相关信息或异常。
- 同步发送：从技术上讲，`Kafka` 生产者始终是异步的————我们发送一条消息，send() 方法返回一个 Future 对象。然而，我们使用 get() 来等待 Future 并在发送下一条记录之前查看 send() 是否成功。
- 异步发送我们使用回调函数调用 send() 方法，该回调函数在收到响应时被触发来自卡夫卡经纪人。


### 同步发送

```java
try {
    producer.send(record).get();
} catch (Exception e) {
    // handle
}
```

`Kafka`Producer 有两种类型的错误。可重试的错误是那些可以通过再次发送消息来解决的错误。例如，可以解决连接错误，因为连接可能会重新建立。当为分区选举新的领导者并刷新客户端元数据时，可以解决`not leader for partition`错误。 `Kafka`Producer 可以配置为自动重试这些错误，因此，只有当重试次数用完且错误未解决时，应用程序代码才会收到可重试的异常。有些错误不会通过重试来解决，例如`Message size Too Large`。在这些情况下，`Kafka`Producer 将不会尝试重试并立即返回异常。

### 异步发送

为了异步发送消息并仍然处理错误情况，生产者支持在发送记录时添加回调`org.apache.kafka.clients.producer.Callback`。

```java
private class DemoProducerCallback implements Callback {
    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
        if (e != null) {
            e.printStackTrace();
        }
    }
}

ProducerRecord<String, String> record =
    new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA");
producer.send(record, new DemoProducerCallback());
```

> 警告：回调在生产者的主线程中执行。这保证了当我们依次向同一个分区发送两条消息时，它们的回调将按照我们发送它们的顺序执行。但这也意味着回调应该相当快，以避免延迟生产者并阻止发送其他消息。不建议在回调中执行阻塞操作。相反，应该使用另一个线程来同时执行任何阻塞操作。

## 配置生产者

### client.id

`client.id` 是客户端及其所使用的应用程序的逻辑标识符。这可以是任何字符串，`broker`将使用它来识别从客户端发送的消息。它用于日志记录和指标以及配额。选择一个好的客户端名称将使故障排除更加容易。

### acks

`acks` 参数控制在生产者认为写入成功之前必须有多少分区副本必须接收记录。默认情况下，`Kafka` 在 `Leader` 收到记录后会响应记录写入成功（Apache `Kafka` 3.0 版本预计将更改此默认值）。此选项对消息的持久性有重大影响，并且根据你的用例，默认值可能不是最佳选择。 `acks` 参数有三个允许值：

- `acks=0`：在假设消息已成功发送之前，生产者不会等待`broker`的回复。这意味着如果出现问题并且`broker`没有收到消息，生产者将不知道，并且消息将丢失。但是，由于生产者不等待服务器的任何响应，因此它可以以网络支持的速度发送消息，因此可以使用此设置来实现非常高的吞吐量。
- `acks=1`：当`Leader`副本收到消息时，生产者将收到来自`broker`的成功响应。如果消息无法写入`Leader`（例如，如果`Leader`崩溃并且尚未选出新`Leader`），生产者将收到错误响应并可以重试发送消息，从而避免潜在的数据丢失。如果`Leader`崩溃并且最新消息尚未复制到新`Leader`，消息仍然可能丢失。
- `acks=all`：一旦所有同步副本收到消息，生产者将收到来自`broker`的成功响应。这是最安全的模式，因为您可以确保多个`broker`都拥有该消息，并且即使发生崩溃，该消息也能继续存在。然而，我们在 `acks=1` 情况下讨论的延迟会更高，因为我们将等待多个`broker`接收消息。

> 使用较低且不太可靠的 `ack` 配置，生产者将能够更快地发送记录。这意味着需要牺牲可靠性来换取生产者延迟。然而，端到端延迟是从记录生成到消费者可以读取的时间开始测量的，并且对于所有三个选项都是相同的。原因是，为了保持一致性，`Kafka`不会允许消费者读取记录，直到它们写入所有同步副本中。因此，如果关心端到端延迟，而不仅仅是生产者延迟，则无需进行权衡：如果选择最可靠的选项，将获得相同的端到端延迟。

### 消息送达时间

生产者有多个配置参数，它们相互作用来控制开发人员最感兴趣的行为之一：调用 send() 成功或失败需要多长时间。这是我们愿意花费的时间，直到 `Kafka` 成功响应，或者直到我们愿意放弃并承认失败。

多年来，配置及其行为已被修改了多次。我们将在这里描述 Apache `Kafka` 2.1 中引入的最新实现。

自 Apache `Kafka` 2.1 以来，我们将发送 ProduceRecord 所花费的时间分为两个单独处理的时间间隔：

- 直到异步调用 send() 返回为止的时间。在此期间，调用 send() 的线程将被阻塞。
- 从异步调用 send() 成功返回到触发回调（成功或失败）。这与从将 Produce​Re⁠cord 放入批次中进行发送直到 `Kafka` 响应成功、不可重试的失败或我们用完分配给发送的时间为止相同。

![](https://raw.githubusercontent.com/shallowinggg/notes/main/images/kafka/delivery-time.png)

### max.block.ms

此参数控制生产者在调用 send() 以及通过partitionsFor() 显式请求元数据时可以阻塞多长时间。当生产者的发送缓冲区已满或元数据不可用时，这些方法可能会阻塞。当达到 `max.block.ms` 时，会抛出超时异常。

### delivery.timeout.ms

此配置将限制从记录准备发送（send() 成功返回并且记录放入批次中）到`broker`响应或客户端放弃所花费的时间，包括重试所花费的时间。如上图所示，该时间应大于 `linger.ms` 和 `request.timeout.ms`。如果尝试创建超时配置不一致的生产者，将收到异常。消息可以比 `delivery.timeout.ms` 更快地成功发送，并且通常会这样。如果生产者在重试时超过了 `delivery.timeout.ms`，则将调用回调，并显示与`broker`在重试之前返回的错误相对应的异常。如果在记录批次仍在等待发送时超出了`delivery.timeout.ms`，则将调用回调并出现超时异常。

> 你可以将传递超时配置为希望等待消息发送的最长时间，通常是几分钟，然后保留默认的重试次数（几乎无限）。使用此配置，只要有时间继续尝试（或直到成功），生产者就会不断重试。这是考虑重试的更合理的方式。我们调整重试的正常流程是：“如果`broker`崩溃，`Leader`选举通常需要 `30` 秒才能完成，所以为了安全起见，让我们继续重试 `120` 秒”。你无需将此心理对话转换为重试次数和重试之间的时间，只需将 `deliver.timeout.ms` 配置为 120 即可。

### request.timeout.ms

该参数控制生产者发送数据时等待服务器回复的时间。请注意，这是在放弃之前等待每个生产者请求返回所花费的时间；它不包括重试、发送前花费的时间等。如果达到超时而没有回复，生产者将重试发送或使用 `TimeoutException`。

### retries 和 retry.backoff.ms

当生产者从服务器收到错误消息时，错误可能是暂时的（例如，缺少分区`Leader`）。在这种情况下， `retries` 参数的值将控制生产者在放弃并通知客户端问题之前重试发送消息的次数。默认情况下，生产者将在重试之间等待 `100ms`，但可以使用 `retry.backoff.ms` 参数来控制这一点。我们建议不要在当前版本的 `Kafka` 中使用这些参数。相反，测试从崩溃的`broker`中恢复需要多长时间（即所有分区获得新的`Leader`需要多长时间），并设置`delivery.timeout.ms`，以便重试所花费的总时间将比`Kafka`集群从崩溃中恢复所花费的时间更长——否则，生产者会过早放弃。

> 如果想完全禁用重试，设置 `retries=0` 是唯一的方法。

### linger.ms

`linger.ms` 控制发送当前批次之前等待其他消息的时间量。当当前批次已满或达到 `linger.ms` 限制时，`Kafka`Producer 会发送一批消息。默认情况下，一旦有发送者线程可用于发送消息，生产者就会立即发送消息，即使批次中只有一条消息。通过将 `linger.ms` 设置为大于 0，我们指示生产者等待一定时间以将其他消息添加到批次中，然后再将其发送到`broker`。这会稍微增加延迟但会显着提高吞吐量 ———— 每条消息的开销要低得多，并且压缩（如果启用）会更好。

### buffer.memory

此配置设置生产者将用于缓冲等待发送到`broker`的消息的内存量。如果应用程序发送消息的速度比传送到服务器的速度快，则生产者可能会耗尽空间，并且额外的 send() 调用将阻塞 `max.block.ms` 并等待空间释放，然后抛出异常。请注意，与大多数生产者异常不同，此超时是由 send() 引发的，而不是由生成的 Future.

### compression.type

默认情况下，消息以未压缩的方式发送。该参数可以设置为snappy、gzip、lz4或zstd，在这种情况下，在将数据发送到`broker`之前将使用相应的压缩算法来压缩数据。 Snappy 压缩是由 Google 发明的，旨在提供良好的压缩比、较低的 CPU 开销和良好的性能，因此在性能和带宽都受到关注的情况下建议使用它。 Gzip 压缩通常会使用更多的 CPU 和时间，但会产生更好的压缩率，因此建议在网络带宽更受限制的情况下使用。通过启用压缩，您可以减少网络利用率和存储，这通常是向 `Kafka` 发送消息时的瓶颈。

### batch.size

当多个记录被发送到同一个分区时，生产者会将它们一起批处理。此参数控制每个批次将使用的内存量（以字节为单位，不是消息！）。当批次满时，该批次中的所有消息都会被发送。然而，这并不意味着生产者将等待批次变满。生产者将发送半满批次，甚至只发送一条消息的批次。因此，`batch.size`设置太大不会导致消息发送延迟；它只会为批次使用更多内存。将批次大小设置得太小会增加一些开销，因为生产者将需要更频繁地发送消息。

### max.in.flight.requests.per.connection

这控制生产者将向服务器发送多少个消息批次而不接收响应。较高的设置可以增加内存使用量，同时提高吞吐量。 [Apache 的 wiki 实验](https://cwiki.apache.org/confluence/display/`Kafka`/An+analysis+of+the+impact+of+max.in.flight.requests.per.connection+and+acks+on+Producer+performance)表明，在单 DC 环境中，只需 2 个正在进行的请求即可实现吞吐量最大化；但是，默认值为 5，并且显示类似的性能。

#### 排序保证

Apache `Kafka` 保留分区内消息的顺序。这意味着，如果消息以特定顺序从生产者发送，`broker`将按该顺序将它们写入分区，并且所有消费者将按该顺序读取它们。将 `retries` 参数设置为非零并将 `max.in.​flight.requests.per.connection` 设置为大于 1 意味着`broker`可能无法写入第一批消息，但成功写入第二批，然后重试第一批并成功，从而颠倒顺序。

由于出于性能原因我们需要至少两个正在进行的请求，并且出于可靠性原因需要大量重试，因此最好的解决方案是设置`enable.idempotence=true`。这保证了最多五个正在进行的请求的消息排序，并且还保证重试不会引入重复。

### max.request.size

此设置控制生产者发送的生产请求的大小。它限制了可以发送的最大消息的大小以及生产者可以在一个请求中发送的消息数量。例如，默认最大请求大小为 1 MB，则可以发送的最大消息为 1 MB，或者生产者可以将 1024 条大小为 1 KB 的消息批处理到一个请求中。此外，`broker`对其接受的最大消息的大小有自己的限制（`message.max.bytes`）。通常最好让这些配置匹配，这样生产者就不会尝试发送被`broker`拒绝的大小的消息。

### receive.buffer.bytes 和 send.buffer.bytes

这些是 TCP 发送的大小以及写入和读取数据时套接字使用的接收缓冲区。如果这些设置为 –1，则将使用操作系统默认值。当生产者或消费者与不同数据中心中的`broker`进行通信时，增加这些参数是一个好主意，因为这些网络连接通常具有较高的延迟和较低的带宽。

### enable.idempotence

从0.11版本开始，`Kafka`支持`exactly-once`语义。 Exactly Once 是一个相当大的主题，但幂等生产者是其中一个简单且非常有益的部分。假设你配置生产者以最大限度地提高可靠性：`acks=all` 和相当大的`delivery.timeout.ms` 以允许足够的重试。这些确保每条消息至少被写入 `Kafka` 一次。在某些情况下，这意味着消息将被多次写入 `Kafka`。例如，假设一个`broker`从生产者接收到一条记录，将其写入本地磁盘，并且该记录已成功复制到其他`broker`，但第一个`broker`在向生产者发送响应之前崩溃了。生产者将等待，直到达到 `request.​time⁠out.ms`，然后重试。重试将转到自上次写入成功复制以来已经拥有该记录副本的新`Leader`，现在会有一个重复的记录。为避免这种情况，可以设置`enable.idempotence=true`。当幂等生产者启用时，生产者将为其发送的每条记录附加一个序列号。如果`broker`收到具有相同序列号的记录，它将拒绝第二个副本，并且生产者将收到无害的 `DuplicateSequenceException`。

## Partitions

在前面的示例中，我们创建的 ProducerRecord 对象包括主题名称、键和值。 `Kafka` 消息是键值对，虽然可以创建仅包含主题和值的 ProducerRecord，且键默认设置为 null，但大多数应用程序都会生成带有键的记录。键有两个目标：它们是与消息一起存储的附加信息，它们通常还用于决定消息将写入哪个主题分区。具有相同键的所有消息将发送至同一分区。这意味着，如果一个进程仅读取主题中分区的子集，则单个键的所有记录都将由同一进程读取。

当key为空并且使用默认分区器时，记录将被随机发送到主题的可用分区之一。`Kafka`将使用循环算法来平衡分区之间的消息。从 Apache `Kafka` 2.4 生产者开始，处理空键时默认分区器中使用的循环算法是粘性的。这意味着它将在切换到下一个分区之前填充发送到单个分区的一批消息。这允许以更少的请求向 `Kafka` 发送相同数量的消息，从而降低延迟并降低`broker`上的 CPU 利用率。

如果存在键并且使用默认分区器，`Kafka` 将对键进行哈希处理（使用自己的哈希算法，因此Java升级时散列值不会改变）并使用结果将消息映射到特定分区。由于键始终映射到同一分区很重要，因此我们使用主题中的所有分区来计算映射，而不仅仅是可用分区。这意味着，如果向特定分区写入数据时不可用，你可能会收到错误，这种情况相当罕见。

除了默认分区器之外，Apache `Kafka` 客户端还提供 `RoundRobinPartitioner` 和 `UniformStickyPartitioner`。即使消息具有键，它们也提供随机分区分配和粘性随机分区分配。当键对于消费应用程序很重要时（例如，有些 ETL 应用程序在将数据从 `Kafka` 加载到关系数据库时使用 `Kafka` 记录中的键作为主键），这些功能非常有用，但工作负载可能会出现偏差，因此单个键可能会产生不成比例的大工作量。使用 `UniformStickyPartitioner` 将导致工作负载在所有分区之间均匀分布。

使用默认分区器时，仅当主题中的分区数量不变时，键到分区的映射才会保持一致。这允许从分区读取数据时进行各种优化。然而，当你向主题添加新分区时，这一点就不再得到保证————旧记录将保留在老分区中，而新记录可能会写入不同的分区。当分区键很重要时，最简单的解决方案是创建具有足够分区的主题并且从不添加分区。

你也可以实现` org.apache.kafka.clients.producer.Partitioner`接口来自定义分区器。


## quotes 和 throttling

当客户端达到配额时，`broker`将开始限制客户端的请求，以防止其超出配额。这意味着`broker`将延迟对客户请求的响应；在大多数客户端中，这将自动降低请求率（因为正在进行的请求数量有限）并将客户端流量降低到配额允许的水平。为了保护`broker`在受到限制时免受行为不当的客户端发送额外请求的影响，`broker`还将在遵守配额所需的时间内静音与客户端的通信通道。

限制行为通过`produce-throttle-time-avg`、`product-throttle-time-max`、`fetch-throttle-time-avg` 和 `fetch-throttle-time-max`向客户端公开，生产请求和获取请求由于限制而延迟的平均时间和最大时间。请注意，该时间可以表示由于生产和消耗吞吐量配额、请求时间配额或两者而导致的限制。其他类型的客户端请求只能由于请求时间配额而受到限制，并且这些请求也将通过类似的指标公开。

> 警告。如果异步发送消息并继续以高于`broker`可以接受速率的速率发送消息，消息将首先在客户端内存中排队。如果发送速率继续高于接受消息的速率，客户端最终将耗尽用于存储多余消息的缓冲区空间，并将阻塞下一个 `Producer.send()` 调用。如果超时延迟不足以让`broker`赶上生产者并清除缓冲区中的一些空间，最终 `Producer.send()` 将抛出 `TimeoutException`。或者，一些已经批量放置的记录将等待超过`delivery.timeout.ms`的时间并过期，从而导致调用`send()`回调并抛出`TimeoutException`。因此，规划和监控非常重要，以确保随着时间的推移，`broker`容量与生产者发送数据的速率相匹配。

