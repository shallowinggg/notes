---
layout: default
title: 可靠数据传输
parent: Kafka
grand_parent: 消息队列
---

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>

## 可靠性保证

- Kafka 提供分区中消息的顺序保证。
- 如果消息B是在消息A之后写入的，使用同一分区中的相同生产者，那么Kafka保证消息B的偏移量将高于消息A，并且消费者将在消息A之后读取消息B。
- 当消息被写入所有同步副本上的分区时（但不一定刷新到磁盘）被视作已提交。生产者可以选择在消息完全提交、写入`Leader`或通过网络发送时接收已发送消息的确认。
- 只要至少有一个副本保持活动状态，已提交的消息就不会丢失。
- 消费者只能读取已提交的消息。

## 复制

Kafka 的复制机制（每个分区有多个副本）是 Kafka 所有可靠性保证的核心。将消息写入多个副本是 Kafka 在发生崩溃时提供消息持久性的方式。

每个 Kafka 主题都分为多个分区，这些分区是基本的数据构建块，分区存储在单个磁盘上。 Kafka 保证分区内事件的顺序，分区可以是在线（可用）或离线（不可用）。每个分区可以有多个副本，其中一个是指定的`Leader`。所有事件都会生成到`Leader`副本，并且通常也会从`Leader`副本中消耗。其他副本只需要与`Leader`保持同步并按时复制所有最近的事件。如果`Leader`变得不可用，则同步副本之一将成为新的`Leader`。

如果副本是分区的`Leader`，或者是符合下述条件的跟随者，则认为副本是同步的：
- 与 ZooKeeper 具有活动会话 ———— 意味着它在过去 6 秒内向 ZooKeeper 发送了心跳（可配置）。
- 在过去 10 秒内从`Leader`拉取消息（可配置）。
- 在过去 10 秒内从`Leader`获取最新消息。也就是说，追随者从`Leader`那里收到消息是不够的，还必须在过去 10 秒内至少有一次没有延迟（可配置）。

如果副本失去与 ZooKeeper 的连接、停止获取新消息或落后且无法在 10 秒内赶上，则该副本将被视为退出同步。当不同步的副本再次连接到 ZooKeeper 并赶上写入`Leader`的最新消息时，它会恢复同步。这通常会在临时网络故障修复后很快发生，但如果存储副本的`broker`停机较长时间，则可能需要一段时间。

## 不同步的副本

在旧版本的 Kafka 中，一个或多个副本在同步和不同步状态之间快速切换的情况并不罕见。这是集群出现问题的明确迹象。一个相对常见的原因是最大请求大小较大和 JVM 堆较大，需要进行调整以防止长时间的垃圾收集暂停，从而导致`broker`暂时与 ZooKeeper 断开连接。如今，这个问题非常罕见，特别是在使用 Apache Kafka 版本 2.5.0 及更高版本及其 ZooKeeper 连接超时和最大副本延迟的默认配置时。将 JVM 版本 8 及更高版本（现在是 Kafka 支持的最低版本）与 G1 垃圾收集器结合使用有助于遏制此问题，尽管大型消息可能仍需要进行调整。有关 Kafka 复制协议演变的详细信息，请参阅 Jason Gustafson 的精彩演讲[Hardening Apache Kafka Replication](https://www.confluent.io/kafka-summit-sf18/hardening-kafka-replication/)，以及 Gwen Shapira 的 Kafka 改进概述[Please Upgrade Apache Kafka Now](https://www.confluent.io/kafka-summit-san-francisco-2019/please-upgrade-apache-kafka-now/)。

稍微落后的同步副本会减慢生产者和消费者的速度 ———— 因为他们在提交消息之前等待所有同步副本获取消息。而一旦副本不同步，我们获取消息时就不再等待它。它仍然落后，但没有性能影响。问题是，同步副本越少，分区的有效复制因子就越低，因此停机或数据丢失的风险就越高。


## broker配置

`broker`中有三个配置参数可以改变 Kafka 在可靠消息存储方面的行为。与许多`broker`配置变量一样，这些变量可以在`broker`级别应用控制系统中所有主题的配置，以及在主题级别应用控制特定主题的行为。

### 复制因子

主题级别的配置是`replication.factor`。在`broker`级别，我们可以控制`default.replication.factor`自动创建主题。

我们一般假设主题的复制因子为三，这意味着每个分区在三个不同的`broker`上复制三次。这是一个合理的假设，因为这是 Kafka 的默认设置，但这是用户可以修改的配置。即使主题存在后，我们也可以选择添加或删除副本，从而使用 Kafka 的副本分配工具修改复制因子。

N 的复制因子允许我们失去 N-1 个`broker`，同时仍然能够向主题读取和写入数据。因此，较高的复制因子可带来更高的可用性、更高的可靠性和更少的灾难。另一方面，对于 N 的复制因子，我们将需要至少 N 个`broker`，并且我们将存储 N 个数据副本，这意味着我们将需要 N 倍的磁盘空间。我们基本上是在用硬件的可用性来交换。

那么我们如何确定一个主题的正确副本数量呢？有几个关键的考虑因素：

- `可用性`。即使在单个`broker`的例行重启过程中，只有一个副本的分区也将变得不可用。我们拥有的副本越多，我们期望的可用性就越高。
- `持久性`。每个副本都是分区中所有数据的副本。如果一个分区只有一个副本，并且磁盘因任何原因变得不可用，那么我们就丢失了该分区中的所有数据。副本越多，尤其是在不同的存储设备上，丢失所有副本的可能性就会降低。
- `吞吐量`。随着每个额外副本的增加，`broker`间流量也会成倍增加。如果我们以 10 MBps 的速率生成分区，则单个副本将不会产生任何复制流量。如果我们有 2 个副本，那么我们将拥有 10 MBps 的复制流量，如果有 3 个副本，则为 20 MBps，如果有 5 个副本，则为 40 MBps。在规划集群大小和容量时，我们需要考虑到这一点。
- `端到端延迟`。每条生成的记录都必须复制到所有同步副本，然后才能供消费者使用。理论上，副本越多，其中一个副本速度有点慢的可能性就越高，因此会减慢消费者的速度。实际上，如果一个`broker`因为任何原因变慢，无论复制因子如何，它都会减慢尝试使用它的每个客户端。
- `成本`。这是对非关键数据使用低于 3 的复制因子的最常见原因。我们拥有的数据副本越多，存储和网络成本就越高。由于许多存储系统已经将每个块复制 3 次，因此有时通过将 Kafka 配置为 2 的复制因子来降低成本是有意义的。请注意，与复制因子 3 相比，这仍然会降低可用性，但持久性将由储存设备保证。

副本的放置也非常重要。 Kafka 将始终确保分区的每个副本都位于单独的`broker`上。在某些情况下，这不够安全。如果某个分区的所有副本都放置在同一机架上的`broker`上，并且架顶交换机出现故障，则无论复制因子如何，我们都将失去该分区的可用性。为了防止机架级灾难，我们建议将`broker`放置在多个机架中，并使用`broker.rack`配置参数为每个`broker`配置机架名称。如果配置了机架名称，Kafka 将确保分区的副本分布在多个机架上，以保证更高的可用性。在云环境中运行 Kafka 时，通常将可用性区域视为单独的机架。

### 不干净的Leader选举

此配置仅在`broker`（实际上是集群范围）级别可用。参数名称是 `unclean.leader.election.enable`，默认情况下设置为 `false`。

当某个分区的 Leader 不再可用时，将选择其中一个同步副本作为新的 Leader 。这种`Leader`选举是“干净的”，因为它保证了已提交的数据不会丢失————根据定义，已提交的数据存在于所有同步副本上。

但是，当除了刚刚变得不可用的`Leader`之外不存在同步副本时，我们该怎么办？这种情况可能发生在以下两种情况之一：
- 分区有三个副本，并且两个追随者变得不可用（假设两个`broker`崩溃了） 。在这种情况下，当生产者继续写入`Leader`时，所有消息都会被确认并提交（因为`Leader`是唯一的同步副本）。现在假设`Leader`变得不可用（哎呀，另一个`broker`崩溃了）。在这种情况下，如果一个不同步的追随者首先启动，我们就会有一个不同步的副本作为该分区唯一可用的副本。
- 该分区有三个副本，并且由于网络问题，两个追随者落后了，因此即使它们启动并进行复制，它们也不再同步。`Leader`作为唯一的同步副本不断接受消息。现在，如果`Leader`变得不可用，则只有不同步的副本可以成为`Leader`。

在这两种情况下，我们都需要做出一个艰难的决定：
- 如果我们不允许不同步的副本成为新的`Leader`，则分区将保持离线状态，直到我们将之前的`Leader`（最后一个同步副本）恢复，副本重新上线。在某些情况下（例如，内存芯片需要更换），这可能需要几个小时。
- 如果我们允许不同步的副本成为新的`Leader`，我们将丢失写入旧`Leader`的所有消息该副本不同步，也会导致消费者出现一些不一致的情况。为什么？想象一下，虽然副本 0 和 1 不可用，但我们将偏移量为 100-200 的消息写入副本 2（当时的`Leader`）。现在副本 2 不可用，副本 0 重新联机。副本 0 仅包含消息 0-100，但没有消息 100-200。如果我们允许副本 0 成为新的`Leader`，它将允许生产者写入新消息并允许消费者读取它们。因此，现在新`Leader`拥有全新的消息 100-200。首先，我们要注意的是，有些消费者可能已经阅读了 100-200 旧消息，有些消费者阅读了 100-200 新消息，有些消费者则两者兼而有之。在查看下游报告等内容时，这可能会导致非常糟糕的后果。此外，副本 2 将重新上线并成为新`Leader`的追随者。那时，它将删除它收到的当前`Leader`上不存在的任何消息。这些消息将来将无法提供给任何消费者。

总之，如果我们允许不同步的副本成为`Leader`，我们将面临数据丢失和不一致的风险。如果我们不允许他们成为`Leader`，我们将面临较低的可用性，因为我们必须等待原始`Leader`在分区重新上线之前变得可用。

默认情况下，`unclean.leader.election.enable` 设置为 `false`，这不允许不同步的副本成为`Leader`。这是最安全的选项，因为它提供了防止数据丢失的最佳保证。这确实意味着在我们之前描述的极端不可用场景中，某些分区将保持不可用，直到手动恢复为止。管理员始终可以查看当前情况，如果决定接受数据丢失以使分区可用，可以在启动集群之前将此配置切换为 `true`，只是不要忘记在集群恢复后将其恢复为 `false`。

### 最小同步副本数

主题和`broker`级别配置都是`min.insync.replicas`。

在某些情况下，即使我们将主题配置为三个副本，也可能会只存在一个同步副本。如果这个副本变得不可用，我们可能必须在可用性和一致性之间做出选择。这从来都不是一个容易的选择。请注意，部分问题在于，根据 Kafka 的可靠性保证，当数据写入所有同步副本时，数据被视为已提交，即使全部仅意味着一个副本，并且如果该副本不可用，数据也可能会丢失。

为了确保提交的数据写入多个副本，我们需要将同步副本的最小数量设置为更高的值。如果一个主题有三个副本，并且我们将 `min.insync.replicas` 设置为 2，那么只有当三个副本中至少有两个同步时，生产者才能写入主题中的分区。

### 保持副本同步

`zookeeper.session.timeout.ms` 是 Kafka `broker`可以停止向 ZooKeeper 发送心跳的时间间隔，而 ZooKeeper 不会认为`broker`已死亡并将其从集群中删除。在2.5.0版本中，该值从6​​秒增加到18秒，以提高Kafka集群在网络延迟表现出较高方差的云环境中的稳定性。一般来说，我们希望这个时间足够高，以避免由垃圾收集或网络条件引起的随机波动，但也要足够低，以确保及时检测到实际上已冻结的`broker`。

如果副本没有从`Leader`拉取消息或者没有赶上`Leader`上的最新消息的时间超过`replica.lag.time.max.ms`，它将变得不同步。在 2.5.0 版本中，该时间从 10 秒增加到 30 秒，以提高集群的弹性并避免不必要的抖动。请注意，这个较高的值还会影响使用者的最大延迟 ———— 使用较高的值时，从消息到达所有副本到允许消费者使用它可能需要长达 30 秒的时间。

### 持久化到磁盘

Kafka 会确认未持久保存到磁盘的消息，确认消息仅取决于接收消息的副本数量。 Kafka 会在轮换段（默认大小为 1 GB）时或重新启动之前将消息刷新到磁盘，但会依赖 Linux 页缓存来刷新消息。其背后的想法是，在单独的机架或可用区域中拥有三台机器，每台机器都有一份数据副本，这比将消息写入`Leader`上的磁盘更安全，因为两个不同机架或区域上同时发生故障的可能性很小。但是，也可以将`broker`配置为更频繁地将消息保存到磁盘。配置参数`flush.messages`允许我们控制不同步到磁盘的消息的最大数量，`flush.ms`允许我们控制同步到磁盘的频率。在使用此功能之前，值得阅读一下 [how fsync impacts Kafka’s throughput and how to mitigate its drawbacks](https://www.confluent.io/blog/kafka-fastest-messaging-system/#fsync)。


## 可靠生产者

每个使用Kafka生产者的人都必须注意两件重要的事情：
- 使用正确的 ack 配置来匹配可靠性要求
- 正确处理配置和代码中的错误

### ack

[ack配置](https://shallowinggg.github.io/notes/mq/kafka/producer.html#acks)

### 重试

处理生产者中的错误分为两部分：生产者自动为我们处理的错误和我们作为使用生产者库的开发人员必须处理的错误。

当生产者向`broker`发送消息时，`broker`可以返回成功代码或错误代码。这些错误代码分为两类：重试后可以解决的错误和无法解决的错误。生产者库可以处理可重试的错误。

一般来说，当我们的目标是永不丢失消息时，我们最好的方法是配置生产者在遇到可重试错误时继续尝试发送消息。重试的最佳方法是将重试次数保留为当前默认值（MAX_INT，或实际上无限），并使用 `delivery.timout.ms` 来配置我们愿意等待的最长时间直到放弃发送消息 ———— 生产者将在此时间间隔内尽可能多次地重试发送消息。

重试发送失败的消息会存在两条消息均已成功写入`broker`的风险，从而导致重复。重试和仔细的错误处理可以保证每条消息至少存储一次，但不恰好存储一次。使用`enable.idempotence=true`将导致生产者在其记录中包含附加信息，`broker`将使用这些信息来跳过由重试引起的重复消息。

### 额外的错误处理

使用内置的生产者重试是正确处理各种错误而不丢失消息的简单方法，但作为开发人员，我们必须能够处理其他类型的错误。其中包括：
- 不可重试的`broker`错误，例如有关消息大小的错误、授权错误等。
- 在消息发送到`broker`之前发生的错误，例如序列化错误
- 当生产者耗尽所有重试尝试或可用内存不足（由于在重试时生产者会存储消息）时发生的错误
- 超时


## 可靠消费者

数据只有在提交到 Kafka 后才可供消费者使用，这意味着它被写入所有同步副本，这意味着消费者获得的数据保证是一致的。消费者唯一要做的就是确保他们跟踪自己已阅读的消息和未阅读的消息。这是在消费消息时不丢失消息的关键。

从分区读取数据时，消费者会获取一批消息，检查该批消息中的最后一个偏移量，然后从收到的最后一个偏移量开始请求另一批消息。这保证了 Kafka 消费者始终能够以正确的顺序获取新数据，而不会丢失任何消息。

当一个消费者停止时，另一个消费者需要知道从哪里开始工作————前一个消费者在停止之前处理的最后一个偏移量是多少？一些消费者将从该分区开始消费，并且它需要知道从哪个偏移量开始。这就是为什么消费者需要提交他们的偏移量。对于它正在使用的每个分区，消费者都会存储其当前位置，因此它或另一个消费者将知道在重新启动后从哪里继续。消费者丢失消息的主要方式是为他们已读取但尚未完全处理的消息提交偏移量。这样，当另一个消费者接手工作时，它将跳过这些消息，并且它们永远不会被处理。这就是为什么仔细注意何时以及如何提交偏移量至关重要。

### 重要参数

为了配置我们的消费者以获得所需的可靠性行为，理解四个消费者配置属性非常重要。

第一个是 `group.id`。基本思想是，如果两个消费者具有相同的组 ID 并订阅同一主题，每个消费者都将被分配主题中分区的子集，因此只会读取消息的子集（但所有消息将由整个组读取）。如果我们需要消费者自行查看其订阅的主题中的每条消息，则它将需要一个唯一的 `group.id`。

第二个相关配置是 `auto.offset.reset`。此参数控制当没有提交偏移量时（例如，当消费者首次启动时）或当消费者请求`broker`中不存在的偏移量时消费者将执行的操作。这里只有两个选择。如果我们选择`earliest`，那么只要分区没有有效的偏移量，消费者就会从分区的开头开始。这可能会导致消费者两次处理大量消息，但它保证最大限度地减少数据丢失。如果我们选择`latest`，消费者将从分区的末尾开始。这最大限度地减少了消费者的重复处理，但几乎肯定会导致消费者错过一些消息。

第三个相关配置是`enable.auto.commit`。这是一个重大决定：我们是要让消费者根据计划为我们提交偏移量，还是计划在代码中手动提交偏移量？自动偏移提交的主要好处是，在我们的应用程序中使用消费者时，少了一件需要担心的事情。当我们在消费者轮询循环中完成对消费记录的所有处理时，自动偏移量提交保证我们永远不会意外提交我们未处理的偏移量。自动偏移提交的主要缺点是我们无法控制应用程序可能处理的重复记录的数量，比如它在处理某些记录之后但在自动提交之前停止了。当应用程序进行更复杂的处理时，例如传递消息到另一个线程在后台处理，别无选择，只能使用手动偏移量提交，因为自动提交可能会提交消费者已读取但可能尚未处理的记录的偏移量。

第四个相关配置`auto.commit.interval.ms`，与第三个相关。如果我们选择自动提交偏移量，则此配置允许我们配置提交偏移量的频率，默认值为每五秒一次。一般来说，更频繁地提交会增加开销，但会减少消费者停止时可能发生的重复消费。

### 手动提交偏移量

如果我们决定需要更多控制并选择手动提交偏移量，则需要关注正确性和性能影响。

#### 处理消息后始终提交偏移量

#### 提交频率是性能和崩溃时重复次数之间的权衡

即使在最简单的情况下，我们在轮询循环内完成所有处理并且不在轮询循环之间维护状态，我们也可以选择在循环内多次提交或选择仅每几次循环提交一次。提交会带来巨大的性能开销。它类似于使用 `acks=all`生产消息，但单个消费者组的所有偏移量提交都会生成到同一个`broker`，这可能会导致过载。提交频率必须平衡性能和重复，在每条消息之后提交只能在吞吐量非常低的主题上进行。

#### 在正确的时间提交正确的偏移量

在轮询循环中间提交偏移量时的一个常见陷阱是意外提交轮询时读取的最后一个偏移量，而不是已处理的偏移量。请记住，在处理消息后始终提交消息的偏移量至关重要 ———— 提交已读取但未处理的消息的偏移量可能会导致消费者丢失消息。

#### 重平衡

在设计应用程序时，我们需要记住消费者会重新平衡，并且我们需要正确处理它们。这通常涉及在撤销分区之前提交偏移量，以及在分配新分区时清除应用程序维护的任何状态。

#### 重试

在某些情况下，调用 `poll` 并处理记录后，有些记录尚未完全处理，需要稍后处理。

当我们遇到可重试错误时，一个选择是提交我们成功处理的最后一条记录。然后，我们将仍然需要处理的记录存储在缓冲区中（因此下一次轮询不会覆盖它们），使用消费者的`pause()`方法来确保其他轮询不会返回数据，并继续尝试处理记录。

遇到可重试错误时的第二个选择是将其写入单独的主题并继续。可以使用单独的消费者组来处理重试主题的重试，或者一个消费者可以订阅主主题和重试主题，但在重试的间隔暂停消费重试主题。此模式类似于许多消息传递系统中使用的死信队列系统。

#### 消费者可能需要维护状态

在某些应用程序中，我们需要在多次调用 `poll` 时维护状态。例如，如果我们想要计算移动平均值，我们需要在每次轮询 Kafka 是否有新消息后更新平均值。如果我们的进程重新启动，我们不仅需要从最后一个偏移量开始消费，而且还需要恢复匹配的移动平均值。实现此目的的一种方法是在应用程序提交偏移量的同时将最新的累积值写入“结果”主题。这意味着当线程启动时，它可以在启动时获取最新的累积值，并从中断处继续获取。一般来说，这是一个需要解决的相当复杂的问题，建议查看像 Kafka Streams 或 Flink 这样的库，它们为聚合、连接、窗口和其他复杂分析提供了类似于 DSL 的高级 API。

## 验证系统可靠性

### 验证配置

与应用程序逻辑隔离地测试`broker`和客户端配置很容易，建议这样做有两个原因：
- 它有助于测试我们选择的配置是否可以满足我们的要求。
- 这是一个很好的推理系统的预期行为的练习。

Kafka 包含两个重要的工具来帮助进行此验证。 `org.apache.kafka.tools` 包包含 `VerifiableProducer` 和 `VerifiableConsumer` 类。它们可以作为命令行工具运行，也可以嵌入到自动化测试框架中。

其想法是，可验证的生产者生成一系列消息，其中包含从 1 到我们选择的值的数字。我们可以像配置我们自己的生产者一样配置可验证的生产者，设置正确的确认次数、重试次数、`delivery.timeout.ms` 以及生成消息的速率。当我们运行它时，它将根据收到的确认打印发送到`broker`的每条消息的成功或错误。可验证的消费者执行补充检查，它消费事件（通常是由可验证生产者产生的事件）并按顺序打印出它消费的事件。它还打印有关提交和重新平衡的信息。

考虑我们要运行哪些测试很重要。例如：
- Leader选举：如果我们杀死Leader会发生什么？生产者和消费者需要多长时间才能重新开始正常工作？
- 控制器选举：控制器重新启动后系统需要多长时间才能恢复？
- 滚动重启：我们能否在不丢失任何消息的情况下逐个重新启动`broker`
- 不干净的`Leader`选举测试：当我们一一杀死一个分区的所有副本（以确保每个副本不同步），然后启动一个不同步的`broker`时，会发生什么？需要做什么才能恢复？这是可以接受的吗？

然后我们选择一个场景，启动可验证的生产者，启动可验证的消费者，并运行该场景 ———— 例如，杀死我们正在向其生成数据的分区的`Leader`。如果我们期望短暂的暂停，然后一切正常恢复而不会丢失消息，那么我们需要确保生产者生成的消息数量和消费者消费的消息数量匹配。

Apache Kafka 库包含[广泛的测试套件](https://github.com/apache/kafka/tree/trunk/tests)。套件中的许多测试都基于相同的原理，并使用可验证的生产者和消费者来确保滚动升级有效。


### 验证应用

一旦我们确定`broker`和客户端配置满足我们的要求，就可以测试应用程序是否提供我们所需的保证。这将检查自定义错误处理代码、偏移提交和重新平衡侦听器以及应用程序逻辑与 Kafka 客户端库交互的类似位置等内容。当然，由于应用程序逻辑可能有很大差异，因此只能提供这么多关于如何进行操作的指导来测试它。建议将应用程序的集成测试作为任何开发过程的一部分，并且在各种故障条件下运行测试：
- 客户端与`broker`之一失去连接
- 客户端和`broker`之间的高延迟
- 磁盘已满
- 磁盘挂起（也称为`brown out`）
- `Leader`选举
- `broker`滚动重启
- 消费者滚动重启
- 生产者滚动重启

有很多工具可以用来引入网络和磁盘故障，而且很多都很优秀，所以不会尝试提出具体的建议。 Apache Kafka 本身包含用于故障注入的 [Trogdor 测试框架](https://cwiki.apache.org/confluence/display/KAFKA/Fault+Injection)。对于每个场景，我们都会有预期的行为，这就是我们在开发应用程序时计划看到的行为。然后我们运行测试来看看实际发生了什么。例如，在计划消费者滚动重启时，我们计划在消费者重新平衡时短暂暂停，然后继续消费，且重复值不超过 1,000 个。我们的测试将显示应用程序提交偏移和处理重新平衡的方式是否真的以这种方式工作。

### 监控

测试应用程序很重要，但它并不能取代持续监控生产系统以确保数据按预期流动的需要。Kafka 的 Java 客户端包括 JMX 指标，这些指标允许监控客户端状态和事件。对于生产者来说，对可靠性最重要的两个指标是每条记录的错误率和重试率（聚合）。请密切关注这些情况，因为错误或重试率上升可能表明系统存在问题。还要监视生产者日志，以了解发送时产生的 `WARN` 级别的错误。生产者上的`ERROR`级别日志消息可能表明发送消息由于不可重试错误、重试次数耗尽的可重试错误或超时而完全失败。如果可以，来自`broker`的确切错误也将被记录。

在消费者方面，最重要的指标是消费者滞后。该指标指示消费者距离提交到`broker`上的分区的最新消息有多远。理想情况下，延迟始终为零，并且消费者将始终阅读最新消息。在实践中，由于调用 `poll()` 返回多条消息，然后消费者在获取更多消息之前花费时间处理它们，因此延迟总是会有点波动。重要的是确保消费者最终能够迎头赶上，而不是越来越落后。由于消费者滞后的预期波动，针对指标设置传统警报可能具有挑战性。 [Burrow](https://github.com/linkedin/Burrow) 是 LinkedIn 的消费者滞后检查工具，可以让这一切变得更容易。

监控数据流还意味着确保及时消耗所有产生的数据（“及时”通常基于业务需求）。为了确保数据被及时消耗，我们需要知道数据是什么时候产生的。 Kafka 对此提供了帮助：从版本 `0.10.0` 开始，所有消息都包含一个时间戳，指示消息生成的时间（请注意，这可以由发送消息的应用程序或`broker`本身覆盖）。

为了确保所有生成的消息在合理的时间内被消耗，我们需要生成消息的应用程序记录生成的消息数（通常为每秒消息数）。消费者需要使用消息时间戳来记录每单位或时间消耗的消息数量，以及从消息产生的时间到消息被消耗的时间的滞后。然后，我们需要一个系统来协调来自生产者和消费者的每秒事件数（以确保途中没有消息丢失），并确保生产时间和消费时间之间的间隔合理。这种类型的端到端监控系统的实施可能具有挑战性且耗时。

除了监控客户端和端到端数据流之外，Kafka `broker`还包括指示从`broker`发送到客户端的错误响应率的指标。我们建议收集 `kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec` 和 `kafka.server:type=BrokerTopicMet⁠rics,name=FailedFetchRequestsPerSec`。有时，会出现某种程度的错误响应，例如，如果我们关闭一个`broker`进行维护，并且在另一个`broker`上选举出新的`Leader`，则生产者将收到 `NOT_LEADER_FOR_PARTITION` 错误，这将导致他们在继续生产前请求更新的元数据。应始终调查失败请求的不明原因增加。为了协助此类调查，失败的请求指标会使用`broker`发送的特定错误响应进行标记。

