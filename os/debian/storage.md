---
layout: default
title: 存储
parent: Debian
grand_parent: 操作系统
---

<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>

# 存储

`RAID`和`LVM`都是从物理对应项（实际的硬盘驱动器或其分区）中提取已安装卷的技术；前者通过引入冗余来确保在硬件故障时数据的安全性和可用性，后者使卷管理更加灵活并且独立于底层磁盘的实际大小。在这两种情况下，系统最终都会获得新的块设备，这些设备可用于创建文件系统或交换空间，而不必将它们映射到一个物理磁盘。 `RAID`和`LVM`来自完全不同的背景，但它们的功能可能有些重叠，这就是为什么它们经常被一起提及。

无论是`RAID`还是`LVM`，内核都提供了一个块设备文件，类似于硬盘驱动器或分区对应的文件。当应用程序或内核的另一部分需要访问此类设备的块时，适当的子系统会将该块路由到相关的物理层。根据配置，此块可以存储在一个或多个物理磁盘上，其物理位置可能与逻辑设备中块的位置没有直接关联。

## Software RAID

`RAID`是指Redundant Array of Independent Disks（独立磁盘冗余阵列）。该系统的目标是防止数据丢失并确保硬盘发生故障时的可用性。总体原理非常简单：数据存储在多个物理磁盘上，而不是仅存储在一个物理磁盘上，并且具有可配置的冗余级别。根据这种冗余量，即使发生意外的磁盘故障，也可以从剩余磁盘无损地重建数据。

`RAID`可以通过专用硬件（集成到 `SCSI` 或 `SATA` 控制器卡中的 `RAID` 模块）或通过软件抽象（内核）来实现。无论是硬件还是软件，具有足够冗余的 `RAID` 系统可以在磁盘出现故障时透明地保持运行；尽管出现故障，堆栈的上层（应用程序）甚至可以继续访问数据。当然，这种`降级模式`会对性能产生影响，并且冗余会减少，因此进一步的磁盘故障可能会导致数据丢失。因此，在实践中，人们会努力只在更换故障磁盘所需的时间内保持这种降级模式。一旦新磁盘到位，`RAID`系统就可以重建所需的数据，从而返回到安全模式。当阵列处于`降级模式`或`重建阶段`时，除了可能降低的访问速度之外，应用程序不会注意到任何事情。

当`RAID`由硬件实现时，其配置通常发生在`BIOS`设置工具中，内核会将`RAID阵列`视为单个磁盘，它将作为标准物理磁盘工作，尽管设备名称可能不同（取决于驱动）。

### RAID级别

`RAID`实际上不是一个单一的系统，而是一系列按级别标识的系统；这些级别的布局和提供的冗余量有所不同。冗余越多，就越能防止故障，因为系统能够继续使用其他磁盘。对应的情况是，给定磁盘组的可用空间会减少；从另一个角度来看，将需要更多的磁盘来存储给定量的数据。

#### Linear RAID

尽管内核的 `RAID` 子系统允许创建`Linear RAID`，但这不是正确的 `RAID`，因为此设置不涉及任何冗余。内核仅端到端聚合多个磁盘，并将生成的聚合卷作为一个虚拟磁盘（一个块设备）提供，这就是它唯一的功能。这种设置很少单独使用，特别是因为缺乏冗余意味着一个磁盘发生故障会使整个聚合（所有数据）不可用。


#### RAID-0

`RAID-0`也不提供任何冗余，但磁盘并不是简单地一个接一个地粘在一起：它们被分成条带，虚拟设备上的块交替存储在物理磁盘上的条带上。例如，在双磁盘 `RAID-0` 设置中，虚拟设备的偶数块将存储在第一个物理磁盘上，而奇数块将最终存储在第二个物理磁盘上。

该系统的目的不是提高可靠性，因为（如在`Linear RAID`下）一旦一个磁盘发生故障，所有数据的可用性都会受到威胁，而是提高性能：在顺序访问大量连续数据期间，内核将能够并行地从两个磁盘读取（或写入），这提高了数据传输速率。这些磁盘完全由 `RAID` 设备使用，因此它们应该具有相同的大小，以免损失性能。

`RAID-0` 的使用正在减少，其利基市场由 `LVM` 填补。

#### RAID-1

`RAID-1`也称为`RAID 镜像`，是最简单且使用最广泛的设置。在其标准形式中，它使用两个相同大小的物理磁盘，并提供相同大小的逻辑卷。数据在两个磁盘上分别存储一份，因此有`镜像`的绰号。当一个磁盘发生故障时，另一磁盘上的数据仍然可用。对于真正关键的数据，`RAID-1`可以设置在两个以上的磁盘上，这会直接影响硬件成本与可用有效负载空间的比率。

`RAID-1`级别虽然昂贵（因为最多只有一半的物理存储空间是有用的），但在实践中被广泛使用。它很容易理解，并且允许非常简单的备份：由于两个磁盘具有相同的内容，因此可以临时提取其中一个而不会对工作系统产生影响。由于内核可以并行读取每个磁盘上一半的数据，因此读取性能通常会提高，而写入性能不会严重下降。对于由 `N` 个磁盘组成的 `RAID-1` 阵列，即使 `N-1` 个磁盘出现故障，数据仍然可用。



#### RAID-4

`RAID-4`级别没有被广泛使用，它使用`N`个磁盘来存储有用的数据，并使用一个额外的`奇偶校验`磁盘来存储冗余信息。如果该磁盘发生故障，系统可以从其他 `N` 个磁盘中重建其内容。如果 `N` 个数据磁盘中的一个发生故障，则剩余的 `N-1` 个磁盘将与`奇偶校验`磁盘相结合来重建所需的数据。

`RAID-4`的开销并不太贵，因为它只增加了 `1/N` 的成本，并且对读取性能没有明显影响，但写入速度会变慢。此外，由于对 `N` 个磁盘中任何一个的写入也涉及对`奇偶校验`磁盘的写入，后者的写入次数比前者多得多，因此其寿命会大大缩短。 `RAID-4` 阵列上的数据仅在（`N+1` 中）一个发生故障时是安全的。

#### RAID-5

`RAID-5` 解决了 `RAID-4` 的不对称问题：奇偶校验块分布在所有 `N+1` 磁盘上，没有单个磁盘具有特定角色。

`RAID-5` 读写性能与 `RAID-4` 相同。同样，系统在最多一个（`N+1`）磁盘出现故障的情况下仍能保持正常运行，但不能再出现更多故障。

#### RAID-6

`RAID-6` 可以被认为是 `RAID-5` 的扩展，其中每`N`个块涉及两个额外的冗余块，并且这组 `N+2`块分布在`N+2`个磁盘上。

`RAID-6`级别比前两个级别稍贵，但它带来了一些额外的安全性，因为最多两个驱动器（`N+2`）可以发生故障，而不会影响数据可用性。与之相对应的是，写操作现在涉及写入一个数据块和两个冗余块，这使得它们变得更慢。

#### RAID-10

严格来说，这不是一个 `RAID` 级别，而是两个 `RAID` 分组的堆叠。从`2×N`块磁盘开始，首先将它们成对地设置为`N`个`RAID-1`卷；然后，通过`Linear RAID`或（越来越多地）通过 `LVM` 将这 `N` 个卷聚合为一个。最后一个案例比纯粹的 RAID 更进一步，但这没有问题。

`RAID-10` 可以承受多个磁盘故障：在上述 `2×N` 阵列中最多可以有 `N` 个磁盘故障，前提是每个 `RAID-1` 对中至少有一个磁盘保持工作。

显然，`RAID` 级别需要根据每个应用程序的限制和要求来选择。请注意，一台计算机可以有多个具有不同配置的不同 `RAID` 阵列。

#### RAID-01

TODO!!

### Setup

设置 `RAID` 卷需要 `mdadm` 软件包；它提供 `mdadm` 命令，允许创建和操作 `RAID` 阵列，以及将其集成到系统其余部分（包括监控系统）的脚本和工具。

> `/proc/mdstat`文件包含现有卷及其状态。创建新的 `RAID` 卷时，应注意不要将其命名为与现有卷相同的名称。

TODO！！！

## LVM

`LVM`（逻辑卷管理器）是另一种从物理支持中抽象出逻辑卷的方法，其重点是提高灵活性而不是提高可靠性。 `LVM` 允许对应用程序透明地更改逻辑卷；例如，可以添加新磁盘、将数据迁移到其中以及删除旧磁盘，而无需卸载卷。

首先，`PV`（Physical Volume）是最接近硬件的实体：它可以是磁盘上的分区，也可以是完整磁盘，甚至是任何其他块设备（包括例如 `RAID` 阵列）。请注意，当物理元素设置为 `LVM` 的 `PV` 时，只能通过 `LVM` 访问它，否则系统会出现混乱。

多个`PV`可以聚集在一个`VG`（Volume Group）中，这可以比作虚拟且可扩展的磁盘。 `VG` 是抽象的，不会出现在 `/dev` 层次结构中的设备文件中，因此直接使用它们没有风险。

第三种对象是`LV`（Logical Volume），它是`VG`的一个chunk；如果我们保留 `VG` 作为磁盘的类比，那么 `LV` 就相当于一个分区。 `LV` 显示为一个块设备，在 `/dev` 中有一个条目，并且可以像任何其他物理分区一样使用（最常见的是托管文件系统或交换空间）。

重要的是，将 `VG` 拆分为 `LV` 完全独立于其物理组件（`PV`）。一个只有单一物理组件（例如磁盘）的`VG`可以被分割成十几个逻辑卷；同样，一个 `VG` 可以使用多个物理磁盘并显示为单个大型逻辑卷。显然，唯一的限制是分配给 `LV` 的总大小不能大于卷组中 `PV` 的总容量。

然而，在 `VG` 的物理组件之间保持某种同质性，并将 `VG` 拆分为具有相似使用模式的逻辑卷，通常是有意义的。例如，如果可用的硬件包括快速磁盘和较慢磁盘，则可以将快速磁盘聚集到一个 `VG`，将较慢磁盘聚集到另一个 `VG`；然后，第一个块的块可以分配给需要快速数据访问的应用程序，而第二个块将保留用于要求较低的任务。

无论如何，请记住，`LV` 并不特别依附于任何一个 `PV`，虽然可以影响 `LV` 数据的物理存储位置，但日常使用不需要这种可能性。相反：当 `VG` 的物理组件集发生变化时，与特定 `LV` 相对应的物理存储位置可以跨磁盘迁移（当然，同时保留在分配给 `VG` 的 `PV` 内）。

### 设置

所需的工具位于 `lvm2` 包及其依赖项中。安装后，设置 `LVM` 需要三个步骤，与三个级别的概念相匹配。

TODO!!!

### 演化

尽管聚合分区或物理磁盘的能力很方便，但这并不是 `LVM` 带来的主要优势。随着时间的推移和需求的变化，它带来的灵活性尤其引人注目。在我们的示例中，我们假设必须存储新的大文件，并且专用于文件服务器的 `LV` 太小而无法容纳它们。

TODO!!!

## RAID vs LVM

一旦人们摆脱了带有单个硬盘的台式计算机的简单情况，并且使用模式不会随着时间的推移而改变，`RAID` 和 `LVM` 都会带来无可争议的优势。然而，`RAID` 和 `LVM` 有两个不同的方向，目标也不同，因此有理由怀疑应该采用哪一个。最合适的答案当然取决于当前和可预见的要求。

在一些简单的情况下，问题并没有真正出现。如果要求是保护数据免受硬件故障的影响，那么显然 `RAID` 将设置在冗余磁盘阵列上，因为 `LVM` 并没有真正解决这个问题。另一方面，如果需要灵活的存储方案，其中卷独立于磁盘的物理布局，那么 `RAID` 就没有多大帮助，`LVM` 将是自然的选择。

> 如果输入/输出速度至关重要，特别是在访问时间方面，那么在众多组合中使用 `LVM` 和/或 `RAID` 可能会对性能产生一些影响，并且这可能会影响选择哪一种决策。然而，这些性能差异确实很小，并且只能在少数用例中才能测量到。如果性能很重要，最有效的办法是使用非旋转存储介质（`solid-state drives`或 `SSD`）；它们每兆字节的成本高于标准硬盘驱动器，并且容量通常较小，但它们提供出色的随机访问性能。如果使用模式包括许多分散在文件系统各处的IO操作，例如对于经常运行复杂查询的数据库，那么在 `SSD` 上运行它们的优势远远超过选择 `LVM` over `RAID`或相反结构。在这些情况下，选择时应考虑其他因素而不是单纯的速度，因为使用 `SSD` 可以最轻松地处理性能方面的问题。

第三个值得注意的用例是当人们只想将两个磁盘聚合到一个卷中时，无论是出于性能原因还是拥有比任何可用磁盘都大的单个文件系统。这种情况可以通过 `RAID-0`（甚至`Linear RAID`）和 `LVM` 卷来解决。在这种情况下，除非有额外的限制（例如，如果计算机仅使用 `RAID`，则与其他计算机保持一致），选择的配置通常是 `LVM`。初始设置几乎没有更复杂，如果需求发生变化或需要添加新磁盘，复杂性的轻微增加足以弥补 `LVM` 带来的额外灵活性。

当然，还有一个非常有趣的用例，即存储系统需要能够抵抗硬件故障，并且在卷分配方面具有灵活性。 `RAID` 和 `LVM` 都无法单独满足这两个要求；无论如何，这就是我们同时使用两者的地方————或者更确切地说，一个在另一个之上。 `RAID`和`LVM`成熟后几乎成为标准的方案是，首先通过将磁盘分组为少量大型`RAID阵列`来保证数据冗余，然后将这些`RAID阵列`用作`LVM` `LV`s；然后将从这些 `LV` 中为文件系统划分逻辑分区。这种设置的卖点是，当磁盘发生故障时，只需要重建少量的 `RAID阵列`，从而减少了管理员恢复所需的时间。

TODO!!! Example


